{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0aea7db9",
   "metadata": {},
   "source": [
    "## 합성곱 층을 부르는 단위\n",
    "Convolution layer를 부르는 단위는 합성곱 신경망의 출처에 따라서 조금 다릅니다. 첫번째 표기 방식은 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU)를 하나의 convolution layer로 보고, max pooling(nn.MaxPoold2d)은 pooling layer로 별도로 명명합니다.<br>\n",
    "두번째 표기 방식은 합성곱(nn.Conv2d) + 활성화 함수(nn.ReLU) + 맥스풀링(nn.MaxPoold2d)를 하나의 convolution layer로 명명합니다.<br>\n",
    "이번 모델은 편의를 위해 두번째 표기 방식을 따르도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a9a2362f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab357c50",
   "metadata": {},
   "source": [
    "1 x 1 x 28 x 28 사이즈의 임의의 tensor를 만듭니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "05d16f8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "텐서의 크기: torch.Size([1, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "# 배치 크기 x 채널 x 높이(height) x 너비(width) 크기의 tensor 선언\n",
    "inputs = torch.Tensor(1, 1, 28, 28)\n",
    "print('텐서의 크기: {}' .format(inputs.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c763f1d",
   "metadata": {},
   "source": [
    "첫번쨰 convolution layer를 구현해보겠습니다. 1 channel의 입력을 받아 32 channel을 뽑아내며, kernel size = 3이고 padding = 1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "155bfb23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv1 = nn.Conv2d(1, 32, 3, padding=1)\n",
    "print(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d1442ca",
   "metadata": {},
   "source": [
    "두번째 convolution layer는 32 channel의 입력을 64 channel로 출력합니다. kernel size = 3, padding = 1입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24d9722d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n"
     ]
    }
   ],
   "source": [
    "conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
    "print(conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbb56ad",
   "metadata": {},
   "source": [
    "이번에는 maxpooling을 구현해보겠습니다. 정수 하나를 인자로 넣으면 kernel size, stride가 둘 다 해당값으로 지정됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78cf31e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n"
     ]
    }
   ],
   "source": [
    "pool = nn.MaxPool2d(2)\n",
    "print(pool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396dc685",
   "metadata": {},
   "source": [
    "## 구현체를 연결하여 model 만들기\n",
    "이제 앞서 선언한 구현체들을 연결하여 모델을 완성해보겠습니다. 우선 입력을 첫번째 convolution layer를 통과시키고, convolution layer를 통과시킨 후의 tensor의 크기를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "deed38f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "out = conv1(inputs)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45fde006",
   "metadata": {},
   "source": [
    "output tensor가 1 batch size, 32 channel, 28 height, 28 width의 size를 갖는 결과를 확인할 수 있습니다. 32가 나온 이유는 out_channel을 32로 지정해주었기 때문입니다. 또한, 28 heigth, 28 width가 나온 이유는 3 x 3 kernel을 사용한 후 padding의 폭을 1로 설정하면 입력의 크기가 보존되기 때문입니다.<br>\n",
    "이제 이를 maxpooling을 통과시키고난 후의 결과를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "855cfb20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 14, 14])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\actgo\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95d86dc",
   "metadata": {},
   "source": [
    "32 channel, 14 height, 14 width의 tensor가 되었습니다. 다시 두번째 convolution layer를 통과시킨 후의 결과를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fea47342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "out = conv2(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1e6d2b",
   "metadata": {},
   "source": [
    "이번에는 64 channel, 14 height, 14 width의 tensor가 결과로 나왔습니다. 64가 나온 이유는 conv2의 out_channel을 64로 지정해주었기 때문입니다. 또한 3 x 3 kernel을 이용해 convolution operation을 진행한 후 1의 폭만큼 padding을 진행하였기 때문에, height, width가 보존된 결과를 확인할 수 있었습니다. 이제 max pooling에 통과시킨 후의 결과를 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcf7891e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 7, 7])\n"
     ]
    }
   ],
   "source": [
    "out = pool(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ffadfc",
   "metadata": {},
   "source": [
    "이제 텐서를 펼치기에 앞서 n번째 차원에 접근할 수 있는 .size(n)에 대해서 배워보겠습니다. size를 사용해 출력한 결과는 아래와 같습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "491f6b37",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "64\n",
      "7\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print(out.size(0))\n",
    "print(out.size(1))\n",
    "print(out.size(2))\n",
    "print(out.size(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ab9a0a",
   "metadata": {},
   "source": [
    "이제 .view() 함수를 이용하여 tensor를 펼치는 작업을 해보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "23b0cd31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3136])\n"
     ]
    }
   ],
   "source": [
    "# 첫번째 차원인 batch size는 그대로 두고 나머지는 펼쳐라.\n",
    "out = out.view(out.size(0), -1)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa510421",
   "metadata": {},
   "source": [
    "Batch size 차원을 제외하고 모두 하나의 차원으로 통합된 것을 볼 수 있습니다. 이제 이에 대해 fully-connected layer를 통과시켜보겠습니다. 출력층으로 10개의 뉴런을 배치하여 10개 차원의 텐서로 변환합니다. (10 size의 one hot vector를 이용해 classification 결과를 표현)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a7b4ad4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "fc = nn.Linear(3136, 10) # input_dim = 3136, output_dim = 10\n",
    "out = fc(out)\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd64c67f",
   "metadata": {},
   "source": [
    "## 3. CNN으로 MNIST classification\n",
    "앞서 선언한 도구들을 이용해 모델을 만들고 training한 후 MNIST dataset을 classification 해보도록 하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d6770629",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76518bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ed2dfc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1da3513b850>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 랜덤 시드를 고정합니다. (매번 같은 결과를 얻기 위해서)\n",
    "torch.manual_seed(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "452d1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용 가능일 경우 랜덤 시드를 고정\n",
    "if(device == 'cuda'):\n",
    "    torch.cuda.manual_seed_all(777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "115b9b19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameter 고정\n",
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aadaf688",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\actgo\\anaconda3\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "mnist_train = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                          train=True, # True를 지정하면 훈련 데이터로 다운로드\n",
    "                          transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/', # 다운로드 경로 지정\n",
    "                         train=False, # False를 지정하면 테스트 데이터로 다운로드\n",
    "                         transform=transforms.ToTensor(), # 텐서로 변환\n",
    "                         download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "87b76784",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = torch.utils.data.DataLoader(dataset=mnist_train,\n",
    "                                         batch_size=batch_size,\n",
    "                                         shuffle=True,\n",
    "                                         drop_last=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf73e5d",
   "metadata": {},
   "source": [
    "이제 모델을 설계합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "90ee61c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        # first layer\n",
    "        # ImgIn shape = (?, 28,28, 1)\n",
    "        # Conv -> (?, 28, 28, 32)\n",
    "        # Pool -> (?, 14, 14, 32)\n",
    "        self.layer1 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # second layer\n",
    "        # ImgIn shape = (?, 14, 14, 32)\n",
    "        # Conv -> (?, 14, 14, 64)\n",
    "        # Pool -> (?, 7, 7, 64)\n",
    "        self.layer2 = torch.nn.Sequential(\n",
    "            torch.nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "        \n",
    "        # fully-connected layer 7x7x64 inputs -> 10 outputs\n",
    "        self.fc = torch.nn.Linear(7*7*64, 10, bias=True)\n",
    "        \n",
    "        # 전결합층 한정으로 가중치 초기화\n",
    "        torch.nn.init.xavier_uniform_(self.fc.weight)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.layer1(x)\n",
    "        out = self.layer2(out)\n",
    "        out = out.view(out.size(0), -1) # 전결합층을 위해 flatten\n",
    "        out = self.fc(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fa3866e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 정의합니다.\n",
    "model = CNN().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f57704f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cost function, optimizer\n",
    "criterion = nn.CrossEntropyLoss().to(device) # cost function에 soft max 함수 포함되어있음\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9666620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 600\n"
     ]
    }
   ],
   "source": [
    "# 총 배치의 수를 출력해보겠습니다.\n",
    "total_batch = len(data_loader)\n",
    "print('총 배치의 수 : {}' .format(total_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21d69891",
   "metadata": {},
   "source": [
    "앞서 batch size를 100으로 설정했는데, 총 배치의 수가 600입니다. 이는 결국 훈련데이터가 총 60,000개 임을 의미합니다.<br>\n",
    "이제 모델을 training 시켜보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "31c21fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] cost = 0.225652859\n",
      "[Epoch:    2] cost = 0.0630322769\n",
      "[Epoch:    3] cost = 0.0462347269\n",
      "[Epoch:    4] cost = 0.0374225415\n",
      "[Epoch:    5] cost = 0.0313504227\n",
      "[Epoch:    6] cost = 0.0260186009\n",
      "[Epoch:    7] cost = 0.0217983592\n",
      "[Epoch:    8] cost = 0.01815827\n",
      "[Epoch:    9] cost = 0.0158862062\n",
      "[Epoch:   10] cost = 0.0130476039\n",
      "[Epoch:   11] cost = 0.0101296436\n",
      "[Epoch:   12] cost = 0.00962105673\n",
      "[Epoch:   13] cost = 0.00865442026\n",
      "[Epoch:   14] cost = 0.00649328902\n",
      "[Epoch:   15] cost = 0.00665707281\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    \n",
    "    for X, Y in data_loader: # 미니 배치 단위로 data를 꺼내옵니다. X는 미니 배치, Y는 label\n",
    "        # image is already size of (28 x 28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = model(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        avg_cost += cost / total_batch\n",
    "        \n",
    "    print('[Epoch: {:>4}] cost = {:>.9}' .format(epoch + 1, avg_cost))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a4e551",
   "metadata": {},
   "source": [
    "X_test data의 batch size가 10000인데, 이 데이터를 모델에 모두 입력하였더니 runtime error가 발생하였습니다.\n",
    "이는 아마 허용된 범위를 추가로? 접근을 하려해서 발생한 문제라고 생각하여 test dataset을 100개만 활용하여 accuracy를 확인하도록 코드를 수정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "da11d2bd",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9799999594688416\n"
     ]
    }
   ],
   "source": [
    "# 학습을 진행하지 않기 때문에 torch.no_grad()\n",
    "with torch.no_grad():\n",
    "    X_test = mnist_test.test_data.view(len(mnist_test), 1, 28, 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "    \n",
    "    prediction = model(X_test[:100])\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test[:100]\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08a4aca9",
   "metadata": {},
   "source": [
    "약 98% 정도의 정확도를 얻을 수 있었습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9f64f4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
